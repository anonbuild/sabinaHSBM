---
title: 'Using *sabinaHSBM* for link prediction and network reconstruction with "marginal_all" method'
output:
  pdf_document:
    latex_engine: xelatex
---

```{r load_pkg, include = FALSE, echo = TRUE, message = FALSE, warning = FALSE, results='hide'}
library(dplyr)
library(ggplot2)
library(reshape2)
library(RColorBrewer)
```

This guide shows a simple use case based on the "marginal_all" method in *sabinaHSBM* to 
detect both missing (false negatives) and/or spurious (false positives) links in an 
incomplete and/or error-prone network.

We use the artificially created dataset `dat2` included in the package to show key functionalities,
including data preparation, link prediction, and network reconstruction.

# Requirements and installation

There are **two ways** to use the package:

## Option A: Docker 

**Non-native UNIX users** or those who prefer to avoid manual dependency installation can 
use the provided **ready-to-use Docker image** which includes R, Python, all dependencies, and
*sabinaHSBM* pre-installed (see Supporting Information S1 for Docker container setup).

Once the container is running, simply load the package in your R session with:

```{r docker, message=FALSE, warning=FALSE, eval = FALSE}
library(sabinaHSBM)
```

## Option B: Native UNIX installation

**Native UNIX users** can run *sabinaHSBM* locally **if** their system includes:

   - R (version $\geq$ 4.0.4) with all required R packages (listed below)
   - Python $\geq$ 3.12.3 with the `graph-tool` library (version $\geq$ 2.45)

```{r setup, message=FALSE, warning=FALSE, eval = FALSE}
install.packages("remotes")
# If the package is not installed, install sabinaHSBM from GitHub
 if (!requireNamespace("sabinaHSBM", quietly = TRUE)) {
   remotes::install_github("anonbuild/sabinaHSBM")
 }

# Load sabinaHSBM
library(sabinaHSBM)
```

Install and load required R packages if not already available:

```{r install_depend, message=FALSE, warning=FALSE, eval = FALSE}
list.of.packages <- c(
  "dplyr",
  "reshape2",
  "reticulate",
  "stringr",
  "tidyr",
  "ROCR"
)

new.packages <-
    list.of.packages[!(list.of.packages %in% installed.packages()[, "Package"])]
if (length(new.packages) > 0) {
  install.packages(new.packages, dependencies = TRUE)
}

for (package in list.of.packages) {
  library(package, character.only = TRUE)
}
```

```{r load_env, include = FALSE}
devtools::load_all("../")
```

```{r start_time}
# Record starting time (optional)
start_time <- Sys.time()
```


# Load example data

The dataset `dat2` is a binary matrix representing a hypothetical species interactions
network. Columns and rows correspond to two different types of nodes (e.g., hosts and parasites),
and links (values of `1`, in red) represent interactions between them while `0` (in white) 
represent lack of an observed interaction. These links are distributed in a pronounced 
structured pattern with some random noise, 
to **focus the example on identifying spurious links**.

```{r load-data}
# Load the dataset
data(dat2, package = "sabinaHSBM")
dat <- dat2
```

```{r plot-data}
# Plot the original matrix
plot_interaction_matrix(adj_mat = dat, order_mat = FALSE)
```

To simulate spurious links and address the `marginal_all` method, we randomly add a small number
of false positives (`1`) to the matrix. This controlled modification allows us to demonstrate how
the method can work with both spurious links (observed but potentially erroneous interactions,
false positives) and missing links (unobserved but likely interactions, false negatives).
In particular, we add a proportion of spurious randomly across all network, 
and a smaller proportion of spurious for nodes with low degree. 

```{r add-spurious-links, echo=TRUE}
# Add spurious links artificially
set.seed(123)
n_spurious <- ceiling(sum(dat) * 0.01) 
n_spurious_rare <- floor(n_spurious/4)
# Find some random spurious
zero_indices <- which(dat == 0)
sampled_indices <- sample(zero_indices, n_spurious)
spurious_links <- arrayInd(sampled_indices, dim(dat))
# Find some spurious targetting nodes with low degree
low_rows <- which(rowSums(dat) == min(rowSums(dat)))
low_cols <- which(colSums(dat) == min(colSums(dat)))
low_links <- as.matrix(expand.grid(low_rows, low_cols))
spurious_rare <- low_links[sample(nrow(low_links),
                                  min(n_spurious_rare, nrow(low_links))), ]
indices_rare <- apply(spurious_rare, 1, 
                      function(x) ((x[2] - 1) * nrow(dat) + x[1]))
# Add spurious to data
spurious_links <- rbind(spurious_links, spurious_rare)
sampled_indices <- c(sampled_indices, indices_rare)
total_spurious <- nrow(spurious_links)
dat[sampled_indices] <- 1
```

We now use the `plot_interaction_matrix()` function to visualize the added spurious in blue.

```{r plot-dat_spur, echo=TRUE}
# Plot the matrix with spurious
dat_spur <- dat
dat_spur[sampled_indices] <- 2
plot_interaction_matrix(dat_spur,
                        col = c("white", "red4", "blue1"),
                        order_mat = FALSE)
```


# Prepare input data for HSBM

The `hsbm.input` function cleans the dataset and creates cross-validation folds by 
temporarily holding out subsets of observed links. In our example, it randomly splits 
observed links into three similar-sized subsets (because here we use 
3-fold cross-validation), holding out
one subset per fold to test the model’s ability to recover removed links. 

We set "max\_held\_per\_fold" to the number of added spurious (`r total_spurious`) to keep the
data more balanced, otherwise, number of removed links would surpass the number of added spurious 
by a large margin hindering inference. To detect spurious it is better to have 
the dataset as complete as possible so overall network structure can be more effectively detected.

```{r prepare-input}
# Prepare input data
n_folds <- 3        # Number of folds for cross-validation
myInput <- hsbm.input(
  dat,              # Binary matrix of observed links
  n_folds = n_folds,
  max_held_per_fold = total_spurious # Maximum number of removed links per fold
)
```

```{r summary-input}
# Summarizes network characteristics
summary(myInput)
```

# Predict link probabilities with "marginal_all"

The `hsbm.predict` function applies the HSBM to predict marginal posterior probabilities of all 
links— both observed (`1s`) and unobserved (`0s`)—so you can identify spurious and missing links 
in one step. The function works directly with the processed input created by 
`hsbm.input`. Computation can be intensive, but parallelization across cores is supported.

```{r parallel-prediction}
# Generate HSBM predictions
myPred <- hsbm.predict(
  myInput,             # Input data processed by hsbm.input()
  iter = 10000,        # Number of iterations
  wait = 10000,         # Number of iterations for MCMC equilibration
  rnd_seed = 123,      # Sets seed in python environment for reproducibility
  method = "marginal_all", # Method for link prediction
  save_blocks = TRUE,  # Save group assignments 
  save_pickle = FALSE, # Save results as pickle files,
  save_plots = FALSE,  # Save hierarchical edge bundling plots
  n_cores = 3
)
```

```{r save-pred, include = FALSE}
save("myPred", file = "mypred_s3.RData")
```

Predicted link probabilities and group assignments are stored for each fold.

Below, we extract the link probabilities (*p*) for fold 1. For example, a high probability 
of an undocumented (reconstructed) link would suggest that this 
interaction is likely real but was missed due to sampling limitations. Conversely, it may 
assign a low *p* to a recorded interaction, indicating it might be spurious. 

```{r prediction-probs}
# View probabilities for fold 1
probabilities_fold1 <- myPred$probs[[1]]
print(probabilities_fold1[sample(1:nrow(probabilities_fold1), 10), ])
```

The group assignments provide the hierarchical clustering structure of nodes for each fold. Let’s 
extract the group assignments for each fold:

```{r prediction-groups}
# Check groups for each fold
print(lapply(myPred$groups,
             function(x){
                 g_cols <- grep("^G", names(x))
                 return(apply(x[g_cols], 2, function(y) length(unique(y))))
             }))
```

Hierarchical group assignments provide insight into how nodes are organized across 
multiple levels. At the first level (G1) nodes are divided into specific groups, reflecting
fine-scale patterns. Moving to higher levels (G2, G3, G4) these groups (or communities) are
progressively aggregated, revealing broader patterns and relationships or communities.

# Network Reconstruction

The `hsbm.reconstructed` function generates a reconstructed binary interaction matrix by combining predictions from all folds. The predicted matrix is transformed to binary values using a user-specified threshold which in this case we set to the value $0.5$.

```{r network-reconstruction, cache = FALSE}
# Network reconstruction
myReconst <- hsbm.reconstructed(
  myPred,                 # Predictions processed by hsbm.predict
  rm_documented=FALSE,    # Remove documented links during validation
  na_treatment = "ignore_na", # Handle NA values in predictions
  threshold = 0.5,            # Binarization threshold
  consistency_matrix = "average_thresholded" # Combine fold predictions
)
```

The `myReconst` object includes the final averaged probability matrix, the final 
reconstructed binary matrix, and evaluation metrics. 

Let’s explore the model overall performance and network reconstruction details.

```{r summary-reconstruction, cache = FALSE}
# View the reconstruction summary and evaluation metrics0
summary(myReconst)
```

The summary above provides the number of spurious and missing links, 
as well as key evaluation metrics, such as the recovery link fraction (RLF).
These results highlight the predicted interactions, showcasing the
method's ability to detect spurious and missing links effectively. 
The HSBM was able to identify 
`r round((sum(myReconst$new_mat[sampled_indices] == 0)/length(sampled_indices)) * 100)`\% of the 
added spurious as erroneously recorded links, and predicted
`r summary(myReconst)[[1]]$missing_links` missing links.
Also it simultaneously recovered an average of
`r round(mean(myReconst$stats$pred_held_ones) * 100)`\% of held-out links across the three folds 
(mean_RLF).

We can now visualize the reconstructed matrix highlighting the predicted missing (in green) 
and spurious links (in blue).

```{r plot_reconstruction_spur, echo=TRUE}
# Plot the matrix with spurious
cols <- c("white", "red4")
dat_spur <- myReconst$data
new_spur <- which(myReconst$data == 1 & myReconst$new_mat == 0)
new_missing <- which(myReconst$data == 0 & myReconst$new_mat == 1)
if(length(new_spur) != 0){
    dat_spur[new_spur] <- 2
    cols <- c(cols, "blue4")
}
if(length(new_missing)!=0){
    dat_spur[new_missing] <- 3
    cols <- c(cols, "green4")
}
plot_interaction_matrix(dat_spur,
                        col = cols, order_mat = FALSE)
```

The heatmap of the probabilities below show that higher probabilities are mostly contained within 
the structured modules. Nodes outside one of the three modules (bottom rows and right columns) 
have a lot of non-sampled interactions (colored grey) possibly representing unlikely interactions. 

```{r heatmap}
library(reshape2)
library(ggplot2)
library(RColorBrewer)
# Create a matrix of averaged probabilities over all folds
mat_avg <- apply(simplify2array(myReconst$pred_mats), 1:2, mean,
                 na.rm = TRUE)

melted_matrix <- melt(mat_avg)
row_names <- rownames(mat_avg)
colnames(melted_matrix) <- c("Rows", "Cols", "Probs")
ggplot(melted_matrix, aes(Cols, Rows, fill= Probs)) + 
  geom_tile() + 
  scale_y_discrete(limits = rev(row_names)) + 
  scale_fill_distiller(palette = "Spectral", direction = 1) +
  theme_minimal() +
  theme(axis.text = element_blank())
```

In most real world networks the threshold of `0.5` is too conservative. Thus, the inspection of
likely spurious can be done by ranking documented edges by their probabilities.

Let's now examine the top 10 predicted links that are most likely to be spurious (false positives)
by visualizing the probabilities of "documented" links in ascending order.

```{r top-links_spur, cache =  FALSE}
# Visualize the top most likely spurious links
top_links_spurious <- top_links(myReconst, 
                                n = 10, 
                                edge_type = "documented")
print(top_links_spurious)
```

We show how we can rank the most likely missing links according to the model.

```{r top-links_missing, cache =  FALSE}
# Visualize the top most likely spurious links
top_links_missing <- top_links(myReconst, 
                               n = 10, 
                               edge_type = "undocumented")
print(top_links_missing)
```

If the task is to do network reconstruction by specifically targetting the insertion of the most
plausible missing links, we can use the probabilities from the `marginal_all` method as 
'scores' in supervised binary classification, which is implemented in *sabinaHSBM* only for 
missing links. 
This is achieved by following the steps in Supporting Information S1, but with 
"method = 'marginal\_all'" in `hsbm.predict()` and optionally "rm\_documented = 'FALSE'" in 
`hsbm.reconstructed()`.

This document demonstrates the use of the *sabinaHSBM* package for network reconstruction. 
By applying the "marginal\_all" method, we showcased how likely spurious and missing links can be
identified and addressed in complex networks.

# Computing characteristics

```{r end_time}
# Show processing time and computer characteristics 
end_time <- Sys.time()
cat("The processing time of this script took: ",
    round(as.numeric(difftime(end_time, start_time, units = "mins", 1))), "minutes\n")
```

This analysis was performed on a Dell Inspiron notebook with the following
characteristics:

- Processor (CPU): Intel Core i7-7500U @ 3.5GHz 
- Memory (RAM): 16 GB
- Operating System: Ubuntu 24.04 (run on a docker image)
- R Version: 4.3.3
